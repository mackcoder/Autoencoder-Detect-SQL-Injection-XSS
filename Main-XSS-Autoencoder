# -*- coding: utf-8 -*-
"""mainXSS-autoencoder.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1cXWyb8QCCnNhwPSI-An__38RDP1fRi0s
"""
'''python 
#Teste colocando arquivo csv de teste no mesmo experimento:

import numpy as np
import pandas as pd
from sklearn.metrics import classification_report, confusion_matrix
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense

# 1. Carregar dados de treino
df_treino = pd.read_csv("XSSTraining.csv")  # Substitua pelo seu arquivo
X = df_treino.drop("Class", axis=1)
y = df_treino["Class"].apply(lambda x: 1 if x == "Malicious" else 0)

# 2. Separar treino e teste
X_treino, X_teste, y_treino, y_teste = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# 3. Normalizar apenas dados normais
escala = StandardScaler()
X_treino_normal = X_treino[y_treino == 0]
X_treino_normal_escala = escala.fit_transform(X_treino_normal)
X_teste_escala = escala.transform(X_teste)

# 4. Criar Autoencoder
input_dim = X.shape[1]
input_layer = Input(shape=(input_dim,))
encoded = Dense(16, activation='relu')(input_layer)
encoded = Dense(8, activation='relu')(encoded)
decoded = Dense(16, activation='relu')(encoded)
decoded = Dense(input_dim, activation='relu')(decoded)

autoencoder = Model(inputs=input_layer, outputs=decoded)
autoencoder.compile(optimizer='adam', loss='mse')

# 5. Treinar Autoencoder
autoencoder.fit(
    X_treino_normal_escala, X_treino_normal_escala,
    epochs=90, batch_size=32, shuffle=True,
    validation_split=0.1, verbose=1
)

# 6. Calcular erro de reconstruÃ§Ã£o
X_recalculo = autoencoder.predict(X_teste_escala)
error = np.mean(np.square(X_teste_escala - X_recalculo), axis=1)

reco_treino = autoencoder.predict(X_treino_normal_escala)
mse_train = np.mean(np.square(X_treino_normal_escala - reco_treino), axis=1)

# 7. Encontrar melhor threshold
porcentagens = range(70, 100, 2)
melhor_recall = 0
melhor_threshold = 0
melhor_resultado = {}

y_teste_numeric = y_teste.values

for x in porcentagens:
    threshold = np.percentile(mse_train, x)
    prev_loop = [1 if i > threshold else 0 for i in error]

    relatorio = classification_report(
        y_teste_numeric, prev_loop,
        target_names=["Normal", "Ataque"],
        output_dict=True
    )
    recall_ataque = relatorio["Ataque"]["recall"]

    if recall_ataque > melhor_recall:
        melhor_recall = recall_ataque
        melhor_threshold = threshold
        melhor_resultado = {
            "percentil": x,
            "precision": relatorio["Ataque"]["precision"],
            "recall": recall_ataque,
            "f1": relatorio["Ataque"]["f1-score"],
            "matriz_confusao": confusion_matrix(y_teste_numeric, prev_loop)
        }

# 8. AvaliaÃ§Ã£o final no conjunto de teste original
prev_y = [1 if e > melhor_threshold else 0 for e in error]

print("ðŸ” AvaliaÃ§Ã£o no conjunto de teste original:")
print("Matriz de ConfusÃ£o:")
print(confusion_matrix(y_teste_numeric, prev_y))

print("\nClassification Report:")
print(classification_report(y_teste_numeric, prev_y, target_names=["Normal", "Ataque"]))

print("\nMelhor Resultado encontrado:")
print(melhor_resultado)

# 9. AvaliaÃ§Ã£o com novo dataset XSStesting
df_xss = pd.read_csv("XSSTesting.csv")  # Substitua pelo seu arquivo
y_xss = df_xss["Class"].apply(lambda x: 1 if x == "Malicious" else 0)
X_xss = df_xss.drop("Class", axis=1)

X_xss_escala = escala.transform(X_xss)
X_xss_reconstruido = autoencoder.predict(X_xss_escala)
erro_xss = np.mean(np.square(X_xss_escala - X_xss_reconstruido), axis=1)

prev_xss = [1 if e > melhor_threshold else 0 for e in erro_xss]

print("\nðŸ§ª AvaliaÃ§Ã£o no dataset XSStesting:")
print("Matriz de ConfusÃ£o:")
print(confusion_matrix(y_xss, prev_xss))

print("\nClassification Report:")
print(classification_report(y_xss, prev_xss, target_names=["Normal", "Ataque"]))
